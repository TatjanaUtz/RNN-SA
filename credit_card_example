import tensorflow as tf
import pandas as pd
import numpy as np
from tensorflow.contrib import rnn
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score


def recurrent_neural_network_model():
    """Design LSTM model."""

    # define shapes of weights and biases manually
    # random value of shape [rnn_size, n_classes] and [n_classes]
    # automatically do this: https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected
    layer = {'weights': tf.Variable(tf.random_normal([n_units, n_classes])),
             'bias': tf.Variable(tf.random_normal([n_classes]))}

    # assign data to x as a sequence: split feature batch along vertical dimension (=1) into 29 slices
    # each slice is an element of the sequence given as input to the LSTM layer
    # (shape of one element of  sequence: [batch_size, 1]
    x = tf.split(xplaceholder, n_features, 1)
    print(x)

    # create LSTM layer and instantiate variables for all gates
    lstm_cell = rnn.BasicLSTMCell(n_units)

    # outputs = outputs of the LSTM layer for each time step
    # states = value of last state of both the hidden states (h and c)
    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)

    # take only the last output of the LSTM layer, multiply it with the previouly defined weight matrix
    # and add the bias value
    # result = logit value of forward propagation
    output = tf.matmul(outputs[-1], layer['weights']) + layer['bias']

    # return logit value
    return output


def train_neural_network():
    """Train and test LSTM model."""
    ''' TRAINING'''
    # get logit value = inverse of activation
    logit = recurrent_neural_network_model()
    # reshape matrix into vector (shape of labels and logits should be equal for feeding into cost function)
    logit = tf.reshape(logit, [-1])

    # define the cost function
    # sigmoid_cross_entropy_with_logits: because of binary classification
    # (for multi class classification: softmax_cross_entropy_with_logits)
    cost = tf.reduce_mean(
        tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=yplaceholder))
    # pass cost to the optimizer
    # AdamOptimizer: because of fairly better performance
    optimizer = tf.train.AdamOptimizer().minimize(cost)

    # create tensorflow session
    with tf.Session() as sess:

        # initialize all global and local variables
        tf.global_variables_initializer().run()
        tf.local_variables_initializer().run()

        # loop over number of iterations (epochs)
        for epoch in range(epochs):
            # reset epoch loss to 0
            epoch_loss = 0

            # define variable to keep track of start and end computation when splitting data into batches
            i = 0
            # Loop over number of batches
            for i in range(int(len(X_train) / batch_size)):
                # keep track from where data was split in each iteration
                start = i
                end = i + batch_size

                # assign a batch of features and labels
                batch_x = np.array(X_train[start:end])
                batch_y = np.array(y_train[start:end])

                # tell tensorflow to run the subgraph necessary to compute the optimizer and the
                # cost by feeding the values in batch_x and batch_y to the placeholders
                # compute value of optimizer and cost and assign them to the variables
                _, c = sess.run([optimizer, cost],
                                feed_dict={xplaceholder: batch_x, yplaceholder: batch_y})
                # add loss of current batch to epoch_loss
                epoch_loss += c
                # raise iterator through data batches
                i += batch_size

            # print total loss of epoch
            print('Epoch', epoch, 'completed out of', epochs, 'loss:', epoch_loss)

        '''TESTING'''
        # feed testing data set into the model and tell tensorflow to run the subgraph necessary to
        # compute logit
        # pass logit value through a sigmoid activation to get prediction
        # round off to remove decimal places of predicted values
        pred = tf.round(tf.nn.sigmoid(logit)).eval(
            {xplaceholder: np.array(X_test), yplaceholder: np.array(y_test)})
        # calculate F1 score = weighted average of precision and recall
        f1 = f1_score(np.array(y_test), pred, average='macro')
        # calculate accurarcy score
        accuracy = accuracy_score(np.array(y_test), pred)
        # calculate recall = ratio of correctly predicted positive observations to all positive observations
        recall = recall_score(y_true=np.array(y_test), y_pred=pred)
        # calculate precision = ratio of correctly predicted positive observations to total predicted positive observations
        precision = precision_score(y_true=np.array(y_test), y_pred=pred)
        # print out all calculated scores
        print("F1 Score:", f1)
        print("Accuracy Score:", accuracy)
        print("Recall:", recall)
        print("Precision:", precision)


if __name__ == "__main__":
    # load data
    data = pd.read_csv('creditcard.csv', skiprows=[0], header=None)

    # seperate loaded data into labels and features
    features = data.iloc[:, 1:30]
    labels = data.iloc[:, -1]

    # divide labels and features into a training and a testing set
    X_train,X_test,y_train,y_test = train_test_split(features, labels, test_size=0.2, shuffle=False, random_state=42)

    # specify hyperparameters
    epochs = 8  # number of iterations to run the data set through the model
    n_classes = 1   # number of classes (binary classification: 0 = normal transaction, 1 = fraudulent transaction)
    n_units = 200   # size of hidden state of the LSTM (both c and h)
    n_features = 29 # number of features in the dataset
    batch_size = 35 # size of each batch of data that is feed into the model

    # define placeholders for data-batches
    xplaceholder= tf.placeholder('float',[None,n_features])
    yplaceholder = tf.placeholder('float')

    # Design, train and test LSTM model
    train_neural_network()

    print("Dummy")